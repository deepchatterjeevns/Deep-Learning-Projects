{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tab-delimited Bilingual Sentence Pairs .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranaya-mathur/Deep-Learning/blob/master/Tab_delimited_Bilingual_Sentence_Pairs_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60aKIKJd9t3",
        "colab_type": "code",
        "outputId": "614ac7e5-2137-4702-e8bb-fac466cc6887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/hin-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-13 08:38:59--  http://www.manythings.org/anki/hin-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90515 (88K) [application/zip]\n",
            "Saving to: ‘hin-eng.zip’\n",
            "\n",
            "\rhin-eng.zip           0%[                    ]       0  --.-KB/s               \rhin-eng.zip         100%[===================>]  88.39K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-05-13 08:38:59 (932 KB/s) - ‘hin-eng.zip’ saved [90515/90515]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCKVC2r_eGXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"hin-eng.zip\", 'r')\n",
        "zip_ref.extractall(\"corpus\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKdqTkS1eP2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aa95cd3-65c7-42a0-fae4-77487f7338ff"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffDwAaTUfl-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some config\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 100  # Number of epochs to train for.\n",
        "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\n",
        "NUM_SAMPLES = 10000  # Number of samples to train on.\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXkZH4YQjsS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ea3322-6453-43a2-91c2-3a772d7cb446"
      },
      "source": [
        "# Where we will store the data\n",
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1\n",
        "\n",
        "\n",
        "# load in the data\n",
        "# download the data at: http://www.manythings.org/anki/\n",
        "t = 0\n",
        "for line in open('corpus/hin.txt'):\n",
        "  # only keep a limited number of samples\n",
        "  t += 1\n",
        "  if t > NUM_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # split up the input and translation\n",
        "  input_text, translation = line.rstrip().split('\\t')\n",
        "\n",
        "  # make the target input and output\n",
        "  # recall we'll be using teacher forcing\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print(\"num samples:\", len(input_texts))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 2831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S08cvsmSWWn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "16155bdd-9740-48f7-e82a-995be58cd905"
      },
      "source": [
        "# tokenize the inputs\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# determine maximum length input sequence\n",
        "max_len_input = max(len(s) for s in input_sequences)\n",
        "\n",
        "# tokenize the outputs\n",
        "# don't filter out special characters\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "\n",
        "\n",
        "# pad the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2392 unique input tokens.\n",
            "Found 3143 unique output tokens.\n",
            "encoder_inputs.shape: (2831, 22)\n",
            "encoder_inputs[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0 1276]\n",
            "decoder_inputs[0]: [   2 1492    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "decoder_inputs.shape: (2831, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf0gZsS1WbJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c1d8c2ed-a70a-455f-d302-6dd97db0929f"
      },
      "source": [
        "# store all the pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(\"glove/glove.6B.100d.txt\") as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUwUEveHWoUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1471cbf0-e6b8-478c-e2d3-1c73382ceb40"
      },
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5USiNF_8WrqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQI7v65EWxSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc5GWynXWzw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3607
        },
        "outputId": "f5bbd31b-1f22-4697-c799-f366923372c5"
      },
      "source": [
        "##### build the model #####\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "# encoder_outputs, h = encoder(x) #gru\n",
        "\n",
        "# keep only the states to pass into decoder\n",
        "encoder_states = [h, c]\n",
        "# encoder_states = [state_h] # gru\n",
        "\n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")\n",
        "\n",
        "# decoder_outputs, _ = decoder_gru(\n",
        "#   decoder_inputs_x,\n",
        "#   initial_state=encoder_states\n",
        "# )\n",
        "\n",
        "# final dense layer for predictions\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Create the model object\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
        "\n",
        "# Compile the model and train it\n",
        "model.compile(\n",
        "  optimizer='rmsprop',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 2264 samples, validate on 567 samples\n",
            "Epoch 1/100\n",
            "2264/2264 [==============================] - 5s 2ms/step - loss: 2.4406 - acc: 0.7147 - val_loss: 2.8537 - val_acc: 0.5838\n",
            "Epoch 2/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 1.5800 - acc: 0.7534 - val_loss: 2.7019 - val_acc: 0.6220\n",
            "Epoch 3/100\n",
            "2264/2264 [==============================] - 3s 2ms/step - loss: 1.4651 - acc: 0.7741 - val_loss: 2.6365 - val_acc: 0.6276\n",
            "Epoch 4/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.3896 - acc: 0.7803 - val_loss: 2.6193 - val_acc: 0.6314\n",
            "Epoch 5/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.3250 - acc: 0.7872 - val_loss: 2.6733 - val_acc: 0.6371\n",
            "Epoch 6/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.2668 - acc: 0.7922 - val_loss: 2.6136 - val_acc: 0.6390\n",
            "Epoch 7/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.2117 - acc: 0.7974 - val_loss: 2.6467 - val_acc: 0.6397\n",
            "Epoch 8/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.1597 - acc: 0.8015 - val_loss: 2.5596 - val_acc: 0.6434\n",
            "Epoch 9/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.1095 - acc: 0.8053 - val_loss: 2.5397 - val_acc: 0.6435\n",
            "Epoch 10/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.0577 - acc: 0.8103 - val_loss: 2.5771 - val_acc: 0.6437\n",
            "Epoch 11/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 1.0101 - acc: 0.8156 - val_loss: 2.5463 - val_acc: 0.6491\n",
            "Epoch 12/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.9627 - acc: 0.8211 - val_loss: 2.5689 - val_acc: 0.6499\n",
            "Epoch 13/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.9160 - acc: 0.8264 - val_loss: 2.5003 - val_acc: 0.6513\n",
            "Epoch 14/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.8699 - acc: 0.8314 - val_loss: 2.5489 - val_acc: 0.6515\n",
            "Epoch 15/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.8261 - acc: 0.8367 - val_loss: 2.5036 - val_acc: 0.6559\n",
            "Epoch 16/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.7816 - acc: 0.8428 - val_loss: 2.5166 - val_acc: 0.6566\n",
            "Epoch 17/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.7383 - acc: 0.8479 - val_loss: 2.4959 - val_acc: 0.6573\n",
            "Epoch 18/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.6976 - acc: 0.8542 - val_loss: 2.5176 - val_acc: 0.6587\n",
            "Epoch 19/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.6554 - acc: 0.8612 - val_loss: 2.5344 - val_acc: 0.6581\n",
            "Epoch 20/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.6160 - acc: 0.8687 - val_loss: 2.5464 - val_acc: 0.6614\n",
            "Epoch 21/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.5764 - acc: 0.8774 - val_loss: 2.5069 - val_acc: 0.6604\n",
            "Epoch 22/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.5394 - acc: 0.8852 - val_loss: 2.5515 - val_acc: 0.6606\n",
            "Epoch 23/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.5036 - acc: 0.8941 - val_loss: 2.5376 - val_acc: 0.6615\n",
            "Epoch 24/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.4677 - acc: 0.9024 - val_loss: 2.5501 - val_acc: 0.6615\n",
            "Epoch 25/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.4330 - acc: 0.9102 - val_loss: 2.5577 - val_acc: 0.6636\n",
            "Epoch 26/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.4001 - acc: 0.9200 - val_loss: 2.5610 - val_acc: 0.6629\n",
            "Epoch 27/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.3695 - acc: 0.9281 - val_loss: 2.5886 - val_acc: 0.6627\n",
            "Epoch 28/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.3388 - acc: 0.9364 - val_loss: 2.5728 - val_acc: 0.6629\n",
            "Epoch 29/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.3117 - acc: 0.9429 - val_loss: 2.6016 - val_acc: 0.6606\n",
            "Epoch 30/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.2840 - acc: 0.9500 - val_loss: 2.6004 - val_acc: 0.6625\n",
            "Epoch 31/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.2584 - acc: 0.9561 - val_loss: 2.6087 - val_acc: 0.6620\n",
            "Epoch 32/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.2354 - acc: 0.9619 - val_loss: 2.6427 - val_acc: 0.6616\n",
            "Epoch 33/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.2127 - acc: 0.9667 - val_loss: 2.6310 - val_acc: 0.6639\n",
            "Epoch 34/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1930 - acc: 0.9710 - val_loss: 2.6430 - val_acc: 0.6633\n",
            "Epoch 35/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1726 - acc: 0.9748 - val_loss: 2.6671 - val_acc: 0.6640\n",
            "Epoch 36/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1561 - acc: 0.9788 - val_loss: 2.6891 - val_acc: 0.6641\n",
            "Epoch 37/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1398 - acc: 0.9823 - val_loss: 2.6889 - val_acc: 0.6637\n",
            "Epoch 38/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1250 - acc: 0.9840 - val_loss: 2.7178 - val_acc: 0.6636\n",
            "Epoch 39/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.1120 - acc: 0.9864 - val_loss: 2.7160 - val_acc: 0.6640\n",
            "Epoch 40/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0992 - acc: 0.9882 - val_loss: 2.7527 - val_acc: 0.6645\n",
            "Epoch 41/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0888 - acc: 0.9897 - val_loss: 2.7385 - val_acc: 0.6635\n",
            "Epoch 42/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0789 - acc: 0.9910 - val_loss: 2.7659 - val_acc: 0.6648\n",
            "Epoch 43/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0699 - acc: 0.9918 - val_loss: 2.7868 - val_acc: 0.6631\n",
            "Epoch 44/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0631 - acc: 0.9924 - val_loss: 2.8016 - val_acc: 0.6637\n",
            "Epoch 45/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0556 - acc: 0.9933 - val_loss: 2.8102 - val_acc: 0.6639\n",
            "Epoch 46/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0495 - acc: 0.9941 - val_loss: 2.8205 - val_acc: 0.6640\n",
            "Epoch 47/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0448 - acc: 0.9942 - val_loss: 2.8411 - val_acc: 0.6644\n",
            "Epoch 48/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0402 - acc: 0.9943 - val_loss: 2.8411 - val_acc: 0.6651\n",
            "Epoch 49/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0363 - acc: 0.9946 - val_loss: 2.8557 - val_acc: 0.6642\n",
            "Epoch 50/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0330 - acc: 0.9948 - val_loss: 2.8952 - val_acc: 0.6648\n",
            "Epoch 51/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0301 - acc: 0.9948 - val_loss: 2.9278 - val_acc: 0.6642\n",
            "Epoch 52/100\n",
            "2264/2264 [==============================] - 3s 2ms/step - loss: 0.0276 - acc: 0.9949 - val_loss: 2.9081 - val_acc: 0.6637\n",
            "Epoch 53/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0250 - acc: 0.9949 - val_loss: 2.9409 - val_acc: 0.6656\n",
            "Epoch 54/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0235 - acc: 0.9947 - val_loss: 2.9247 - val_acc: 0.6633\n",
            "Epoch 55/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0215 - acc: 0.9949 - val_loss: 2.9674 - val_acc: 0.6639\n",
            "Epoch 56/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0204 - acc: 0.9950 - val_loss: 2.9465 - val_acc: 0.6644\n",
            "Epoch 57/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0186 - acc: 0.9953 - val_loss: 2.9732 - val_acc: 0.6655\n",
            "Epoch 58/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0181 - acc: 0.9951 - val_loss: 2.9951 - val_acc: 0.6646\n",
            "Epoch 59/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0170 - acc: 0.9949 - val_loss: 3.0154 - val_acc: 0.6650\n",
            "Epoch 60/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 3.0325 - val_acc: 0.6644\n",
            "Epoch 61/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 3.0558 - val_acc: 0.6643\n",
            "Epoch 62/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0149 - acc: 0.9949 - val_loss: 3.0367 - val_acc: 0.6646\n",
            "Epoch 63/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0140 - acc: 0.9953 - val_loss: 3.0648 - val_acc: 0.6664\n",
            "Epoch 64/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0135 - acc: 0.9953 - val_loss: 3.0637 - val_acc: 0.6656\n",
            "Epoch 65/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0131 - acc: 0.9954 - val_loss: 3.0799 - val_acc: 0.6638\n",
            "Epoch 66/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0127 - acc: 0.9953 - val_loss: 3.0986 - val_acc: 0.6652\n",
            "Epoch 67/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0124 - acc: 0.9953 - val_loss: 3.0983 - val_acc: 0.6642\n",
            "Epoch 68/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0120 - acc: 0.9953 - val_loss: 3.1039 - val_acc: 0.6646\n",
            "Epoch 69/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0117 - acc: 0.9951 - val_loss: 3.1314 - val_acc: 0.6650\n",
            "Epoch 70/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0112 - acc: 0.9954 - val_loss: 3.1120 - val_acc: 0.6644\n",
            "Epoch 71/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0112 - acc: 0.9952 - val_loss: 3.1634 - val_acc: 0.6653\n",
            "Epoch 72/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0109 - acc: 0.9952 - val_loss: 3.1890 - val_acc: 0.6652\n",
            "Epoch 73/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0107 - acc: 0.9953 - val_loss: 3.1798 - val_acc: 0.6646\n",
            "Epoch 74/100\n",
            "2264/2264 [==============================] - 3s 2ms/step - loss: 0.0104 - acc: 0.9953 - val_loss: 3.1675 - val_acc: 0.6647\n",
            "Epoch 75/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0105 - acc: 0.9952 - val_loss: 3.2197 - val_acc: 0.6657\n",
            "Epoch 76/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0102 - acc: 0.9955 - val_loss: 3.2299 - val_acc: 0.6644\n",
            "Epoch 77/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0101 - acc: 0.9953 - val_loss: 3.2038 - val_acc: 0.6659\n",
            "Epoch 78/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0100 - acc: 0.9952 - val_loss: 3.2154 - val_acc: 0.6647\n",
            "Epoch 79/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0098 - acc: 0.9953 - val_loss: 3.2166 - val_acc: 0.6647\n",
            "Epoch 80/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0095 - acc: 0.9952 - val_loss: 3.2384 - val_acc: 0.6660\n",
            "Epoch 81/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0097 - acc: 0.9954 - val_loss: 3.2562 - val_acc: 0.6657\n",
            "Epoch 82/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0094 - acc: 0.9952 - val_loss: 3.2554 - val_acc: 0.6646\n",
            "Epoch 83/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0095 - acc: 0.9953 - val_loss: 3.2845 - val_acc: 0.6643\n",
            "Epoch 84/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0093 - acc: 0.9953 - val_loss: 3.2888 - val_acc: 0.6650\n",
            "Epoch 85/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0091 - acc: 0.9954 - val_loss: 3.2848 - val_acc: 0.6629\n",
            "Epoch 86/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0090 - acc: 0.9953 - val_loss: 3.3005 - val_acc: 0.6653\n",
            "Epoch 87/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0089 - acc: 0.9953 - val_loss: 3.3007 - val_acc: 0.6644\n",
            "Epoch 88/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0091 - acc: 0.9954 - val_loss: 3.3194 - val_acc: 0.6630\n",
            "Epoch 89/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0089 - acc: 0.9954 - val_loss: 3.3071 - val_acc: 0.6651\n",
            "Epoch 90/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0085 - acc: 0.9955 - val_loss: 3.3276 - val_acc: 0.6653\n",
            "Epoch 91/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0092 - acc: 0.9953 - val_loss: 3.3309 - val_acc: 0.6637\n",
            "Epoch 92/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0088 - acc: 0.9955 - val_loss: 3.3445 - val_acc: 0.6654\n",
            "Epoch 93/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0088 - acc: 0.9952 - val_loss: 3.3691 - val_acc: 0.6646\n",
            "Epoch 94/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0086 - acc: 0.9953 - val_loss: 3.3523 - val_acc: 0.6638\n",
            "Epoch 95/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0087 - acc: 0.9953 - val_loss: 3.3433 - val_acc: 0.6642\n",
            "Epoch 96/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0085 - acc: 0.9952 - val_loss: 3.3713 - val_acc: 0.6651\n",
            "Epoch 97/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0085 - acc: 0.9951 - val_loss: 3.3601 - val_acc: 0.6659\n",
            "Epoch 98/100\n",
            "2264/2264 [==============================] - 3s 1ms/step - loss: 0.0086 - acc: 0.9954 - val_loss: 3.3693 - val_acc: 0.6669\n",
            "Epoch 99/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0085 - acc: 0.9953 - val_loss: 3.3787 - val_acc: 0.6644\n",
            "Epoch 100/100\n",
            "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0084 - acc: 0.9953 - val_loss: 3.4031 - val_acc: 0.6654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bWgaByPW4UT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "f80888d7-a745-407c-8ae1-d49b84012a0b"
      },
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='acc')\n",
        "plt.plot(r.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYzZifXQYe1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# this time, we want to keep the states too, to be output\n",
        "# by our sampling model\n",
        "decoder_outputs, h, c = decoder_lstm(\n",
        "  decoder_inputs_single_x,\n",
        "  initial_state=decoder_states_inputs\n",
        ")\n",
        "# decoder_outputs, state_h = decoder_lstm(\n",
        "#   decoder_inputs_single_x,\n",
        "#   initial_state=decoder_states_inputs\n",
        "# ) #gru\n",
        "decoder_states = [h, c]\n",
        "# decoder_states = [h] # gru\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The sampling model\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\n",
        "# outputs: y(t), h(t), c(t)\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs_single] + decoder_states_inputs, \n",
        "  [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABNMY3FzYj2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + states_value\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "    # states_value = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55sEkP8QYnsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fd314bb7-d639-4555-991a-2e91b61b918b"
      },
      "source": [
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: Turn off the light, please.\n",
            "Translation: बत्ती बंद करदो, प्लीज़।\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Would you speak more slowly, please?\n",
            "Translation: आप थोड़ा धीरे बोल सकते हैं क्या?\n",
            "Continue? [Y/n]N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ul_w4cYp3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}